{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinatorics: Count non trivial dead graphs of Nest (example below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from numba.typed import Dict, List\n",
    "from numba import njit\n",
    "from anonymigraph.anonymization._external.nest_model.fast_rewire import create_neighborhood_dict, get_block_indices\n",
    "from anonymigraph.anonymization._external.nest_model.fast_rewire import (\n",
    "    get_block_indices,\n",
    "    sort_edges,\n",
    ")\n",
    "\n",
    "def count_dead_subgraph(edges, colors):\n",
    "    edges_ordered, edges_classes, dead_arr, is_mono = sort_edges(edges, colors, is_directed=False)\n",
    "    block_indices = get_block_indices(edges_classes, dead_arr)\n",
    "\n",
    "    old_alive_total_color_subgraphs, true_additional_dead_color_subgraphs = _count_dead_subgraph(\n",
    "        edges_ordered,\n",
    "        edges_classes[:, 0],\n",
    "        is_mono[0],\n",
    "        block_indices[0],\n",
    "    )\n",
    "\n",
    "    num_colors = np.unique(colors).size\n",
    "    all_possible_color_subgraphs = num_colors * (num_colors + 1) // 2\n",
    "    color_subgraphs_with_edges = np.unique(edges_classes[:, 0]).size\n",
    "\n",
    "    return all_possible_color_subgraphs, color_subgraphs_with_edges, old_alive_total_color_subgraphs, true_additional_dead_color_subgraphs\n",
    "\n",
    "#@njit(cache=True)\n",
    "def _count_dead_subgraph(edges, edge_class, is_mono_color, block):\n",
    "    old_alive_total_subgraphs = 0\n",
    "    true_additional_dead_subgraphs = 0\n",
    "    old_additional_dead_subgraphs = 0\n",
    "\n",
    "    for i in range(len(block)):\n",
    "        lower = block[i, 0]\n",
    "        upper = block[i, 1]\n",
    "        current_class = edge_class[lower]\n",
    "        block_edges = edges[lower:upper]\n",
    "\n",
    "        if is_mono_color.get(current_class, False):\n",
    "            any_swaps_possible = _is_there_any_edge_swap_possible_mono(block_edges)\n",
    "        else:\n",
    "            any_swaps_possible = _is_there_any_edge_swap_possible_bipartite(block_edges)\n",
    "\n",
    "        if not any_swaps_possible:\n",
    "            true_additional_dead_subgraphs += 1\n",
    "\n",
    "        if np.unique(block_edges[:, 0]).size == 1 or np.unique(block_edges[:, 1]).size == 1:\n",
    "            old_additional_dead_subgraphs += 1 # there\n",
    "\n",
    "        old_alive_total_subgraphs += 1\n",
    "\n",
    "\n",
    "    assert old_additional_dead_subgraphs <= 2 # this is a bug the last or first block is not correctly assigned as dead this should be 0 really\n",
    "\n",
    "    return old_alive_total_subgraphs, true_additional_dead_subgraphs\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def _is_there_any_edge_swap_possible_mono(edges):\n",
    "    num_edges = len(edges)\n",
    "    neigh = create_neighborhood_dict(edges)\n",
    "\n",
    "    for index1 in range(num_edges):\n",
    "        for index2 in range(num_edges):\n",
    "            if index1 == index2:\n",
    "                continue\n",
    "            for i2_1 in range(2):\n",
    "                i2_1 = np.random.randint(0, 2)\n",
    "                i2_2 = 1 - i2_1\n",
    "                e1_l, e1_r = edges[index1, :]\n",
    "                e2_l = edges[index2, i2_1]\n",
    "                e2_r = edges[index2, i2_2]\n",
    "\n",
    "                if (e1_r == e2_r) or (e1_l == e2_l):  # swap would do nothing\n",
    "                    continue\n",
    "\n",
    "                if (e1_l == e2_r) or (e1_r == e2_l):  # no self loops after swap\n",
    "                    continue\n",
    "\n",
    "                if e2_r in neigh[e1_l] or e1_r in neigh[e2_l]:\n",
    "                    # we cant swap\n",
    "                    pass\n",
    "                else:\n",
    "                    # we can swap\n",
    "                    return True\n",
    "    # no swaps at all\n",
    "    return False\n",
    "\n",
    "@njit(cache=True)\n",
    "def _is_there_any_edge_swap_possible_bipartite(edges):\n",
    "    \"\"\"Rewires a bipartite network specified in edges\n",
    "\n",
    "    This is optimized for larger networks and uses a dictionary lookup to avoid multi edges\n",
    "    \"\"\"\n",
    "\n",
    "    delta = len(edges)\n",
    "    neigh = Dict()\n",
    "    neigh[0] = List([-1])\n",
    "    del neigh[0]\n",
    "    for l, r in edges:\n",
    "        if l not in neigh:\n",
    "            tmp = List([-1])\n",
    "            tmp.pop()\n",
    "            neigh[l] = tmp\n",
    "        neigh[l].append(r)\n",
    "\n",
    "    for index1 in range(delta):\n",
    "        for index2 in range(delta):\n",
    "            if index1 == index2:\n",
    "                continue\n",
    "            e1_l, e1_r = edges[index1, :]\n",
    "            e2_l, e2_r = edges[index2, :]\n",
    "\n",
    "            if (e1_r == e2_r) or (e1_l == e2_l):  # swap would do nothing\n",
    "                continue\n",
    "\n",
    "            if (e1_l == e2_r) or (e1_r == e2_l):  # no self loops after swap\n",
    "                continue\n",
    "\n",
    "            if e2_r in neigh[e1_l] or e1_r in neigh[e2_l]:\n",
    "                # we cant swap\n",
    "                pass\n",
    "            else:\n",
    "                # we can swap\n",
    "                return True\n",
    "    # no swaps at all\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the graph below contains no valid edge swaps even though it is not classified as \"dead\" by original nest. This is infact a complex combinatorial problem that heavily complicates stochastic approaches to analyze nest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from([0, 1, 2], bipartite=0)  # Group 1\n",
    "G.add_nodes_from([3, 4], bipartite=1)    # Group 2\n",
    "G.add_edges_from([(0, 3), (1, 3), (2, 3), (1, 4)])\n",
    "\n",
    "colors = np.array([0,0,0,1,1])\n",
    "\n",
    "edges = np.array(G.edges(), dtype=np.uint32)\n",
    "\n",
    "all_possible_color_subgraphs, color_subgraphs_with_edges, old_alive_total_color_subgraphs, true_additional_dead_color_subgraphs = count_dead_subgraph(edges, colors.reshape(1, -1))\n",
    "print(f\"possible color subgraphs: {all_possible_color_subgraphs} of those non-empty: {color_subgraphs_with_edges} of those are alive by org nest: {old_alive_total_color_subgraphs} of those are additional dead: {true_additional_dead_color_subgraphs}\")\n",
    "\n",
    "pos = nx.bipartite_layout(G, [0,1,2])\n",
    "nx.draw(G, pos, with_labels=True, node_color=['skyblue' if node in [0,1,2] else 'lightgreen' for node in G.nodes()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Graph Bound / Convergence tool for graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "def largest_eigen(A, num_iters=None, tol=None):\n",
    "    if num_iters is None:\n",
    "        num_iters = float('inf')  # By default only stop once tolerance criteria is met\n",
    "    if tol is None:\n",
    "        tol = 1e-12\n",
    "\n",
    "    n = A.shape[0]  # Size of the matrix\n",
    "    vec = np.ones(n)  # Starting with a constant vector\n",
    "\n",
    "    iter_count = 0  # Initialize iteration counter\n",
    "    while iter_count < num_iters:  # Loop until num_iters or convergence\n",
    "        vec_next = A @ vec + vec\n",
    "        norm = np.linalg.norm(vec_next)\n",
    "        vec_diff = vec_next / norm - vec\n",
    "        vec = vec_next / norm\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.linalg.norm(vec_diff) < tol:\n",
    "            break\n",
    "\n",
    "        # Warn if exceeding 10,000 iterations\n",
    "        if iter_count == 10000:\n",
    "            print(\"Iteration count exceeded 10,000. Consider increasing tolerance or checking the matrix for convergence properties.\")\n",
    "        if iter_count == 100000:\n",
    "            print(\"Iteration count exceeded 100,000. Consider increasing tolerance or checking the matrix for convergence properties.\")\n",
    "        if iter_count == 1000000:\n",
    "            print(\"Iteration count exceeded 1,000,000. Consider increasing tolerance or checking the matrix for convergence properties.\")\n",
    "\n",
    "        iter_count += 1\n",
    "\n",
    "    eigenvalue = (vec.T @ (A @ vec)) / (vec.T @ vec)  # Rayleigh quotient for eigenvalue\n",
    "\n",
    "    if not np.all(vec > 0):\n",
    "        raise ValueError(\"The adjusted eigenvector does not have all positive entries.\")\n",
    "\n",
    "    return eigenvalue, vec\n",
    "\n",
    "\n",
    "def largest_eigen_integer(A, num_iters=1890*10, tol=None):\n",
    "    n = A.shape[0]  # Size of the matrix\n",
    "    vec = np.ones(n, dtype=object)  # Use dtype=object for arbitrary-precision integers\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        vec_next = A.dot(vec) + vec  # Sparse matrix-vector multiplication + integer addition\n",
    "        # Normalization and convergence checks are challenging with integers and may need adjustment\n",
    "\n",
    "        vec = vec_next  # Placeholder, actual normalization to be adjusted\n",
    "\n",
    "    # Estimating eigenvalue with integers requires careful handling, possibly via Rayleigh quotient approximation\n",
    "\n",
    "    return vec\n",
    "\n",
    "def eigen_gap(A):\n",
    "    val, _ = eigsh(A, k=2, which='LA')\n",
    "    return val[1] - val[0]\n",
    "\n",
    "def k_biggest_ev(A, k=1):\n",
    "    val, _ = eigsh(A, k=k, which='LA')\n",
    "    return val\n",
    "\n",
    "def get_delta(A, lam, x):\n",
    "    return A @ x - lam * x\n",
    "\n",
    "def calculate_kmeans_cluster_loss(x, cluster_labels, centroids, mode=2):\n",
    "    assert mode == 2\n",
    "    total_loss = 0\n",
    "    for i, color in enumerate(cluster_labels):\n",
    "        centroid = centroids[color]\n",
    "        distance = (x[i] - centroid) ** 2\n",
    "        total_loss += distance\n",
    "    return np.sqrt(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anonymigraph.anonymization._external.nest_model._rewire import _rewire\n",
    "import optimal1dclustering\n",
    "\n",
    "from anonymigraph.anonymization._external.nest_model.fast_wl import WL_fast\n",
    "\n",
    "def get_convergence_data_of_nest(G, min_cluster_size = 1, printing = False, max_k = float(\"Inf\"), max_iter=None, tol=None, random_seed=44):\n",
    "    if not nx.is_connected(G):\n",
    "        raise ValueError(\"G is not connected, spectral gap may be 0 nothing holds anymore.\")\n",
    "    A_G = nx.adjacency_matrix(G).astype(np.float64)  # Get the adjacency matrix as a sparse matrix\n",
    "    lam_G, x = largest_eigen(A_G, max_iter, tol)\n",
    "    _, max_degree = max(G.degree(), key=lambda pair: pair[1])\n",
    "    spectral_gap = eigen_gap(A_G)\n",
    "\n",
    "    print(\"Dominant eigenvalue:\", lam_G)\n",
    "    print(\"max_degree:\", max_degree)\n",
    "    print(\"spectral_gap\", spectral_gap)\n",
    "\n",
    "    data_dict = {}\n",
    "    for k in range(1, min(G.number_of_nodes()//min_cluster_size, max_k)):\n",
    "        results = {}\n",
    "        mode = 2\n",
    "        colors, centroids = optimal1dclustering.cluster(\n",
    "            x, k, mode=mode, min_cluster_size=min_cluster_size\n",
    "        )\n",
    "        colors = np.array(colors)\n",
    "        clusterLoss = calculate_kmeans_cluster_loss(x, colors, centroids, mode = mode)\n",
    "\n",
    "        # Get new synthetic graph with Variation Nest\n",
    "        edges = np.array(G.edges(), dtype=np.uint32)\n",
    "        edges_rewired = _rewire(edges, colors.reshape(1, -1), r=10, parallel=False, random_seed=random_seed) # r=10 to ensure we really did enough flips to be burned in\n",
    "        Ga = nx.Graph()\n",
    "        Ga.add_nodes_from(G.nodes(data=True))\n",
    "        Ga.add_edges_from(edges_rewired)\n",
    "\n",
    "        # dead subgraph statistics\n",
    "        is_G_a_connected = int(nx.is_connected(Ga))\n",
    "        all_possible_color_subgraphs, color_subgraphs_with_edges, old_alive_total_color_subgraphs, true_additional_dead_color_subgraphs = count_dead_subgraph(edges, colors.reshape(1, -1))\n",
    "\n",
    "        # Get graph spectrum statistics\n",
    "        A_Ga = nx.adjacency_matrix(Ga).astype(np.float64)\n",
    "        delta = get_delta(A_Ga, lam_G, x)\n",
    "        delta_norm = np.linalg.norm(delta)\n",
    "        lam_Ga, x_Ga = largest_eigen(A_Ga, max_iter, tol)\n",
    "        eigenvec_diff_norm = np.linalg.norm(x - x_Ga)\n",
    "\n",
    "        #eigenvec_diff_norm_bound = 2*max_degree*clusterLoss / spectral_gap # provable approx upper bound\n",
    "        eigenvec_diff_norm_bound = 2*lam_G*clusterLoss / spectral_gap # approx approx upper bound\n",
    "        #eigenvec_diff_norm_bound = lam_G*clusterLoss / spectral_gap # probably approx uppper bound tight\n",
    "\n",
    "        if eigenvec_diff_norm > eigenvec_diff_norm_bound and k > 4 and is_G_a_connected == 1:\n",
    "            print(\"BREAKPOINT\")\n",
    "            print(\"BREAKPOINT\")\n",
    "            \"\"\"\n",
    "            graph = G\n",
    "            color_by = x\n",
    "            import matplotlib.pyplot as plt\n",
    "            from matplotlib.colors import Normalize\n",
    "            plt.figure(dpi=300)\n",
    "            norm = Normalize(vmin=color_by.min(), vmax=color_by.max())\n",
    "            cmap = plt.cm.get_cmap('inferno')\n",
    "            pos = nx.circular_layout(graph)\n",
    "            #pos = nx.spring_layout(graph, iterations = 1000)\n",
    "            nx.draw(graph, pos, with_labels=False, font_size=3, node_size=7, node_color=\"white\")\n",
    "            for i, (node, color_val) in enumerate(zip(graph.nodes, color_by)):\n",
    "                plt.text(pos[node][0], pos[node][1], str(node), fontsize=3, ha='center', va='center', color=cmap(norm(color_val)))\n",
    "                #plt.text(pos[node][0], pos[node][1], str(node), fontsize=3, ha='center', va='center', color=cmap(norm(color_val)))\n",
    "            plt.show()\n",
    "            \"\"\"\n",
    "\n",
    "        # Saving stats\n",
    "        results['all_possible_color_subgraphs'] = all_possible_color_subgraphs\n",
    "        results['color_subgraphs_with_edges'] = color_subgraphs_with_edges\n",
    "        results['old_alive_total_color_subgraphs'] = old_alive_total_color_subgraphs\n",
    "        results['true_additional_dead_color_subgraphs'] = true_additional_dead_color_subgraphs\n",
    "        results['is_G_a_connected'] = is_G_a_connected\n",
    "\n",
    "        results['Clustering Loss'] = clusterLoss\n",
    "        results['Delta L2 Magnitude'] = delta_norm\n",
    "        results['Delta L2 Magnitude / Lambda_G'] = delta_norm/lam_G\n",
    "        results['Eigenvec L2 Norm Diff'] = eigenvec_diff_norm\n",
    "        results['Eigenvec L2 Norm Diff Bound'] = eigenvec_diff_norm_bound\n",
    "        results['Dominant Lambda Diff'] = lam_Ga - lam_G\n",
    "\n",
    "        data_dict[k] = results\n",
    "\n",
    "        if printing:\n",
    "            print(\"-\"*30)\n",
    "            print(f\"{k}: Clustering Loss\", clusterLoss)\n",
    "            print(f\"{k}: possible color subgraphs: {all_possible_color_subgraphs} of those non-empty: {color_subgraphs_with_edges} of those are alive by org nest: {old_alive_total_color_subgraphs} of those are additional dead: {true_additional_dead_color_subgraphs}\")\n",
    "\n",
    "            print(f\"{k}: Eigenvec L2 Norm Diff:\", eigenvec_diff_norm)\n",
    "            print(f\"{k}: Eigenvec L2 Norm Diff Bound:\", eigenvec_diff_norm_bound)\n",
    "            print(f\"{k}: Delta L2 Magnitude\", delta_norm)\n",
    "            print(f\"{k}: Delta L2 Magnitude / Lambda_G\", delta_norm/lam_G)\n",
    "            print(f\"{k}: Dominant Lambda Diff:\", lam_Ga - lam_G)\n",
    "            print(f\"{k}: is_G_a_connected:\", is_G_a_connected)\n",
    "        else:\n",
    "            print(f\"{k}:\")\n",
    "\n",
    "\n",
    "    edges = np.array(G.edges(), dtype=np.uint32)\n",
    "    bidirectional_edges = np.row_stack((edges, edges[:, [1, 0]]))\n",
    "    all_depth_colors = WL_fast(bidirectional_edges, labels=None, max_iter=None)\n",
    "\n",
    "    print(f\"Calculating Performance of Original Nest, with {len(all_depth_colors)} depths\")\n",
    "    original_nest = {}\n",
    "    for i in range(len(all_depth_colors)):\n",
    "\n",
    "        print(f\"{i}: Calculating Nest at depth {i}\")\n",
    "\n",
    "        colors = all_depth_colors[i].reshape(1, -1)\n",
    "        edges_rewired = _rewire(\n",
    "            edges, colors, r=10, parallel=False, random_seed=random_seed # r=10 to ensure we really did enough flips to be burned in\n",
    "        )\n",
    "        k_approx = len(np.unique(colors))\n",
    "        if k_approx > max_k:\n",
    "            continue\n",
    "\n",
    "        Ga = nx.Graph()\n",
    "        Ga.add_nodes_from(G.nodes(data=True))\n",
    "        Ga.add_edges_from(edges_rewired)\n",
    "\n",
    "        A_Ga = nx.adjacency_matrix(Ga).astype(np.float64)\n",
    "        lam_Ga, x_Ga = largest_eigen(A_Ga, max_iter, tol)\n",
    "        eigenvec_diff_norm = np.linalg.norm(x - x_Ga)\n",
    "\n",
    "        results = {}\n",
    "        results['Eigenvec L2 Norm Diff'] = eigenvec_diff_norm\n",
    "\n",
    "        original_nest[k_approx] = results\n",
    "\n",
    "\n",
    "    return {\"data_dict\": data_dict, \"original_nest\":original_nest}\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_convergence_data(data, title, plot_nest=True):\n",
    "    data_dict = data[\"data_dict\"]\n",
    "\n",
    "    # Create traces for each metric\n",
    "    traces = []\n",
    "    traces.append(go.Scatter(x=list(data_dict.keys()),\n",
    "                                    y=[data_dict[k]['Clustering Loss'] for k in data_dict.keys()],\n",
    "                                    mode='lines',#+markers',\n",
    "                                    name=r'$\\ell$'))\n",
    "    #traces.append(go.Scatter(x=list(data_dict.keys()),\n",
    "    #                            y=[data_dict[k]['Delta L2 Magnitude'] for k in data_dict.keys()],\n",
    "    #                            mode='lines+markers',\n",
    "    #                            name='Delta L2 Magnitude'))\n",
    "    #traces.append(go.Scatter(x=list(data_dict.keys()),\n",
    "    #                            y=[data_dict[k]['Delta L2 Magnitude / Lambda_G'] for k in data_dict.keys()],\n",
    "    #                            mode='lines+markers',\n",
    "    #                            name='Delta L2 Magnitude / Lambda_G'))\n",
    "    #traces.append(go.Scatter(x=list(data_dict.keys()),\n",
    "    #                             y=[data_dict[k]['Dominant Lambda Diff'] for k in data_dict.keys()],\n",
    "    #                             mode='lines+markers',\n",
    "    #                             name='Dominant Lambda Diff'))\n",
    "    traces.append(go.Scatter(x=list(data_dict.keys()),\n",
    "                                    y=[data_dict[k]['Eigenvec L2 Norm Diff'] for k in data_dict.keys()],\n",
    "                                    mode='lines',#+markers',\n",
    "                                    name=r'$\\left\\Vert v_1 - v`_1\\right\\Vert_2$'))\n",
    "    traces.append(go.Scatter(x=list(data_dict.keys()),\n",
    "                                    y=[data_dict[k]['Eigenvec L2 Norm Diff Bound'] for k in data_dict.keys()],\n",
    "                                    mode='lines',#+markers',\n",
    "                                    name=r'$\\textrm{Bound on }\\left\\Vert v_1 - v`_1\\right\\Vert_2\\textrm{ first order perturbation}$'))\n",
    "\n",
    "    traces.append(go.Scatter(x=list(data_dict.keys()),\n",
    "                            y=[data_dict[k]['color_subgraphs_with_edges'] for k in data_dict.keys()],\n",
    "                            mode='lines',#+markers',\n",
    "                            name='Color Subgraphs with edges',\n",
    "                            yaxis='y2'))  # This assigns the trace to the second y-axis\n",
    "\n",
    "    traces.append(go.Scatter(x=list(data_dict.keys()),\n",
    "                            y=[data_dict[k]['old_alive_total_color_subgraphs'] for k in data_dict.keys()],\n",
    "                            mode='lines',#+markers',\n",
    "                            name='non-dead color subgraphs (as defined in original nest)',\n",
    "                            yaxis='y2'))  # This assigns the trace to the second y-axis\n",
    "\n",
    "    traces.append(go.Scatter(x=list(data_dict.keys()),\n",
    "                            y=[data_dict[k]['true_additional_dead_color_subgraphs'] for k in data_dict.keys()],\n",
    "                            mode='lines',#+markers',\n",
    "                            name='Additional dead color subgraphs',\n",
    "                            yaxis='y2'))  # This assigns the trace to the second y-axis\n",
    "\n",
    "    traces.append(go.Scatter(x=list(data_dict.keys()),\n",
    "                            y=[data_dict[k]['is_G_a_connected'] for k in data_dict.keys()],\n",
    "                            mode='lines',#+markers',\n",
    "                            name='1 if sampled graph is connected',\n",
    "                            yaxis='y2'))  # This assigns the trace to the second y-axis\n",
    "\n",
    "    if plot_nest:\n",
    "        original_nest = data[\"original_nest\"]\n",
    "\n",
    "        traces.append(go.Scatter(x=list(original_nest.keys()),\n",
    "                y=[original_nest[k]['Eigenvec L2 Norm Diff'] for k in original_nest.keys()],\n",
    "                mode='markers',\n",
    "                name=\"Original Nest k=len(wl-colors)\",\n",
    "                marker=dict(symbol='x', size=10)))\n",
    "\n",
    "    layout_loglog = go.Layout(title=title,\n",
    "                            xaxis_title='k',\n",
    "                            yaxis_title='Metric Values (Log Scale)',\n",
    "                            yaxis_type='log',  # Set y-axis to log scale\n",
    "                            # Add a second y-axis to the layout\n",
    "                            yaxis=dict(\n",
    "                                exponentformat='e',  # Use scientific notation for the primary y-axis\n",
    "                            ),\n",
    "                            yaxis2=dict(title='Color Subgraph Count Metrics',\n",
    "                                        titlefont=dict(color='rgba(148, 103, 189, 1)'),\n",
    "                                        tickfont=dict(color='rgba(148, 103, 189, 1)'),\n",
    "                                        overlaying='y',  # This places the second y-axis on top of the first\n",
    "                                        side='right',  # This places the second y-axis on the right\n",
    "                                        type='linear'),  # Set the second y-axis to linear scale\n",
    "                            hovermode='closest',\n",
    "                            height=900,\n",
    "                            legend=dict(\n",
    "                                    orientation=\"h\",\n",
    "                                    x=0.5,\n",
    "                                    y=-0.1,\n",
    "                                    xanchor=\"center\",\n",
    "                                    yanchor=\"top\"\n",
    "                                )\n",
    "                            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Add the new trace to the figure\n",
    "    fig = go.Figure(data=traces, layout=layout_loglog)\n",
    "    fig.layout.template = 'simple_white+gridon' # 'presentation'\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LFR graphs exponential degree sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a Graph\n",
    "n = 400\n",
    "tau1 = 3\n",
    "tau2 = 1.5\n",
    "mu = 0.1\n",
    "G = nx.LFR_benchmark_graph(\n",
    "    n, tau1, tau2, mu, average_degree=10, min_community=80, seed=10\n",
    ")\n",
    "G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "data_dict = get_convergence_data_of_nest(G, min_cluster_size = 1, max_k=10)\n",
    "plot_convergence_data(data_dict, f\"LFR Graph: n={n}, τ1={tau1}, τ2={tau2}, μ={mu}, AvgDeg=10, MinComm=80\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erdos Renyis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.05\n",
    "n = 150\n",
    "G = nx.erdos_renyi_graph(n, p)\n",
    "data_dict = get_convergence_data_of_nest(G, min_cluster_size = 1, max_k = 150)\n",
    "plot_convergence_data(data_dict, f\"Erdős-Rényi: n={n}, p={p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.1\n",
    "n = 150\n",
    "G = nx.erdos_renyi_graph(n, p)\n",
    "data_dict = get_convergence_data_of_nest(G, min_cluster_size = 1, max_k = 150)\n",
    "plot_convergence_data(data_dict, f\"Erdős-Rényi: n={n}, p={p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.25\n",
    "n = 150\n",
    "G = nx.erdos_renyi_graph(n, p)\n",
    "data_dict = get_convergence_data_of_nest(G, min_cluster_size = 1, max_k = 150)\n",
    "plot_convergence_data(data_dict, f\"Erdős-Rényi: n={n}, p={p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.5\n",
    "n = 150\n",
    "G = nx.erdos_renyi_graph(n, p)\n",
    "data_dict = get_convergence_data_of_nest(G, min_cluster_size = 1, max_k = 150)\n",
    "plot_convergence_data(data_dict, f\"Erdős-Rényi: n={n}, p={p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.95\n",
    "n = 150\n",
    "G = nx.erdos_renyi_graph(n, p)\n",
    "data_dict = get_convergence_data_of_nest(G, min_cluster_size = 1, max_k = 150)\n",
    "plot_convergence_data(data_dict, f\"Erdős-Rényi: n={n}, p={p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worst Case: Path Graphs\n",
    "- almost certain that the cases where the bound is violated are numeric errors from clustering/power iteration, can't easily increase resolution either as optimalclustering works on floats no matter what"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 30  # Number of nodes for both graphs\n",
    "G = nx.path_graph(n)\n",
    "\n",
    "print(\"G edges\", G.number_of_edges())\n",
    "\n",
    "data_dict = get_convergence_data_of_nest(G, min_cluster_size = 1)\n",
    "plot_convergence_data(data_dict, f\"Path Graph: Length={n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 101  # Number of nodes for both graphs\n",
    "G = nx.path_graph(n)\n",
    "\n",
    "print(\"G edges\", G.number_of_edges())\n",
    "\n",
    "data_dict = get_convergence_data_of_nest(G, min_cluster_size = 1)\n",
    "plot_convergence_data(data_dict, f\"Path Graph: Length={n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200  # Number of nodes for both graphs\n",
    "expected_edges = 3\n",
    "total_possible_edges = n * (n - 1) / 2\n",
    "p = expected_edges / total_possible_edges  # Probability for Erdos-Renyi graph\n",
    "\n",
    "# Generating the path and Erdos-Renyi graphs with specified parameters\n",
    "seed = 3\n",
    "path_graph_redefined = nx.path_graph(n)\n",
    "G_erdos_renyi_redefined = nx.gnp_random_graph(n, p, seed=seed)\n",
    "G = nx.compose(path_graph_redefined, G_erdos_renyi_redefined)\n",
    "\n",
    "print(\"G edges\", G.number_of_edges())\n",
    "\n",
    "data_dict = get_convergence_data_of_nest(G, min_cluster_size = 1)\n",
    "plot_convergence_data(data_dict, f\"Path + Random Edges: n={n}, #RandomEdges={G.number_of_edges() - path_graph_redefined.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200  # Number of nodes for both graphs\n",
    "expected_edges = 3\n",
    "total_possible_edges = n * (n - 1) / 2\n",
    "p = expected_edges / total_possible_edges  # Probability for Erdos-Renyi graph\n",
    "\n",
    "# Generating the path and Erdos-Renyi graphs with specified parameters\n",
    "path_graph_redefined = nx.path_graph(n)\n",
    "G_erdos_renyi_redefined = nx.gnp_random_graph(n, p, seed=1)\n",
    "G = nx.compose(path_graph_redefined, G_erdos_renyi_redefined)\n",
    "\n",
    "print(\"G edges\", G.number_of_edges())\n",
    "\n",
    "data_dict = get_convergence_data_of_nest(G, min_cluster_size = 1)\n",
    "plot_convergence_data(data_dict, f\"Path + Random Edges: n={n}, #RandomEdges={G.number_of_edges() - path_graph_redefined.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 201\n",
    "G = nx.path_graph(n)\n",
    "G.add_edge(50, 150)\n",
    "G.add_edge(95, 105)\n",
    "\n",
    "data_dict = get_convergence_data_of_nest(G, min_cluster_size = 1, max_k = 100, random_seed=333, tol=1e-7)\n",
    "plot_convergence_data(data_dict, f\"Bound Failure: Dominant Eigenvector Switching: Path + Random Edges: n={n}, #RandomEdges={2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Graphs (also difficult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "r = 4\n",
    "d = 5\n",
    "n = r**d - 1\n",
    "G = nx.full_rary_tree(r, n)\n",
    "\n",
    "data_dict = get_convergence_data_of_nest(G, min_cluster_size = 1, max_k = 100)\n",
    "plot_convergence_data(data_dict, f\"r-ary Tree: r={r}, Depth={d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "r = 2\n",
    "d = 8\n",
    "n = r**d - 1\n",
    "G = nx.full_rary_tree(r, n)\n",
    "\n",
    "data_dict = get_convergence_data_of_nest(G, min_cluster_size = 1, max_k = 100)\n",
    "plot_convergence_data(data_dict, f\"r-ary Tree: r={r}, Depth={d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 2\n",
    "d = 8\n",
    "n = r**d - 1\n",
    "print(n)\n",
    "avg_degree = r+1 # tree has degree = r+1\n",
    "p_sparse = avg_degree/n*0.01\n",
    "print(\"Expected noisy edges added:\", n**2*p_sparse)\n",
    "G = nx.compose(nx.erdos_renyi_graph(n, p_sparse), nx.full_rary_tree(r, n))\n",
    "\n",
    "data_dict = get_convergence_data_of_nest(G, min_cluster_size = 1, max_k = 300)\n",
    "plot_convergence_data(data_dict, f\"Noisy r-ary Tree: r={r}, Depth={d}, Noise={p_sparse*100:.5f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d regular Graphs\n",
    "- WL and EV is constant for exact d regular graphs. d regular graphs are however great expanders i.e. have a big spectral gap so bound should be good here.\n",
    "- need to slightly pertub them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 109\n",
    "expected_edges = 10\n",
    "total_possible_edges = p * (p - 1) / 2\n",
    "p_sparse = expected_edges / total_possible_edges  # Probability for Erdos-Renyi graph\n",
    "\n",
    "Gpaley = nx.paley_graph(p).to_undirected()\n",
    "G = nx.compose(nx.erdos_renyi_graph(p, p_sparse, seed=57), Gpaley)\n",
    "print(f\"number of edges in Gpaley {Gpaley.number_of_edges()} number of edges added by noise {G.number_of_edges() - Gpaley.number_of_edges()}\")\n",
    "\n",
    "data_dict = get_convergence_data_of_nest(G, min_cluster_size = 1, max_k = 100)\n",
    "plot_convergence_data(data_dict, f\"Paley Graph + Noise: p={p}, NoiseLevel={p_sparse*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 400\n",
    "d = 3\n",
    "G = nx.random_regular_graph(d, n)\n",
    "data_dict = get_convergence_data_of_nest(G, min_cluster_size = 1)\n",
    "plot_convergence_data(data_dict, \"d-Regular Graphs have a constant perron eigenvector still, this shows the upper bound works even here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failure Mode: Dominant Eigenvector Switching\n",
    "## Original has for this reason also extremely passive bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens here is that the dominant vector switches\n",
    "# My theorem only proofs that the CURRENT dominant vector (like the fixed one) changes pertubatively - it doesnt make a statement on whether another eigenvector can become the new \"king\"\n",
    "\n",
    "# (A' - lam) = (A - Pperp (A' - A) Pperp - lam) x = Pperp (A' - A) Pperp x\n",
    "\n",
    "G = nx.cycle_graph(100)\n",
    "G.add_edges_from([\n",
    "    (50-20, 50+20), # edge used to build a triangle\n",
    "])\n",
    "A_G = nx.adjacency_matrix(G).astype(np.float64)  # Get the adjacency matrix as a sparse matrix\n",
    "lam_G, x = largest_eigen(A_G)\n",
    "_, max_degree = max(G.degree(), key=lambda pair: pair[1])\n",
    "spectral_gap = eigen_gap(A_G)\n",
    "\n",
    "print(\"Dominant eigenvalue:\", lam_G)\n",
    "print(\"spectral_gap\", spectral_gap)\n",
    "\n",
    "colors, centroids = optimal1dclustering.cluster(\n",
    "    x, k=30, mode=2, min_cluster_size=1\n",
    ")\n",
    "colors = np.array(colors)\n",
    "clusterLoss = calculate_kmeans_cluster_loss(x, colors, centroids)\n",
    "eigenvec_diff_norm_bound = 2*max_degree*clusterLoss / spectral_gap # provable approx upper bound\n",
    "#eigenvec_diff_norm_bound = 2*lam_G*clusterLoss / spectral_gap # approx approx upper bound\n",
    "#eigenvec_diff_norm_bound = lam_G*clusterLoss / spectral_gap # probably approx uppper bound tight\n",
    "\n",
    "\n",
    "Ga = nx.cycle_graph(200)\n",
    "Ga.add_edges_from([\n",
    "    (50-1,50+1), # triangle\n",
    "    (150-3, 150+3), # fixed because nest fixes it via colors\n",
    "])\n",
    "A_Ga = nx.adjacency_matrix(Ga).astype(np.float64)  # Get the adjacency matrix as a sparse matrix\n",
    "lam_Ga, x_Ga = largest_eigen(A_Ga)\n",
    "spectral_gap_Ga = eigen_gap(A_Ga)\n",
    "\n",
    "\n",
    "# Plot G\n",
    "graph = G\n",
    "color_by = x\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "plt.figure(dpi=300)\n",
    "norm = Normalize(vmin=color_by.min(), vmax=color_by.max())\n",
    "cmap = plt.cm.get_cmap('inferno')\n",
    "pos = nx.circular_layout(graph)\n",
    "nx.draw(graph, pos, with_labels=False, font_size=3, node_size=7, node_color=\"white\")\n",
    "for i, (node, color_val) in enumerate(zip(graph.nodes, color_by)):\n",
    "    plt.text(pos[node][0], pos[node][1], colors[node], fontsize=3, ha='center', va='center', color=cmap(norm(color_val)))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot Ga\n",
    "graph = Ga\n",
    "color_by = x_Ga\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "plt.figure(dpi=300)\n",
    "norm = Normalize(vmin=color_by.min(), vmax=color_by.max())\n",
    "cmap = plt.cm.get_cmap('inferno')\n",
    "pos = nx.circular_layout(graph)\n",
    "#pos = nx.spring_layout(graph, iterations = 1000, seed = 17)\n",
    "nx.draw(graph, pos, with_labels=False, font_size=3, node_size=7, node_color=\"white\")\n",
    "for i, (node, color_val) in enumerate(zip(graph.nodes, color_by)):\n",
    "    plt.text(pos[node][0], pos[node][1], str(node), fontsize=3, ha='center', va='center', color=cmap(norm(color_val)))\n",
    "    #plt.text(pos[node][0], pos[node][1], str(node), fontsize=3, ha='center', va='center', color=cmap(norm(color_val)))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graphs to test\n",
    "- reynold erneys\n",
    "- power law graphs\n",
    "- expander graphs \n",
    "- cliques\n",
    "- trees and cliques that are d-regular\n",
    "- graphs with large eigengap and ones with small\n",
    "- real world graphs\n",
    "- try to design a graph for which the number of alive sub colographs only sinks extremely slowly\n",
    "- always test with different min_cluster sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
